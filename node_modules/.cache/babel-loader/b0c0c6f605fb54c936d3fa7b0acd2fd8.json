{"ast":null,"code":"import { GraphQLError as e } from \"graphql/error/GraphQLError.mjs\";\nimport { Kind as r } from \"graphql/language/kinds.mjs\";\nimport { parse as t } from \"graphql/language/parser.mjs\";\nimport { print as n } from \"graphql/language/printer.mjs\";\nimport { make as a } from \"wonka\";\n\nfunction rehydrateGraphQlError(r) {\n  if (\"string\" == typeof r) {\n    return new e(r);\n  } else if (\"object\" == typeof r && r.message) {\n    return new e(r.message, r.nodes, r.source, r.positions, r.path, r, r.extensions || {});\n  } else {\n    return r;\n  }\n}\n\nvar o = function (e) {\n  function CombinedError(r) {\n    var t = r.networkError;\n    var n = r.response;\n    var a = (r.graphQLErrors || []).map(rehydrateGraphQlError);\n\n    var o = function generateErrorMessage(e, r) {\n      var t = \"\";\n\n      if (void 0 !== e) {\n        return t = \"[Network] \" + e.message;\n      }\n\n      if (void 0 !== r) {\n        r.forEach(function (e) {\n          t += \"[GraphQL] \" + e.message + \"\\n\";\n        });\n      }\n\n      return t.trim();\n    }(t, a);\n\n    e.call(this, o);\n    this.name = \"CombinedError\";\n    this.message = o;\n    this.graphQLErrors = a;\n    this.networkError = t;\n    this.response = n;\n  }\n\n  if (e) {\n    CombinedError.__proto__ = e;\n  }\n\n  (CombinedError.prototype = Object.create(e && e.prototype)).constructor = CombinedError;\n\n  CombinedError.prototype.toString = function toString() {\n    return this.message;\n  };\n\n  return CombinedError;\n}(Error);\n\nfunction phash(e, r) {\n  e |= 0;\n\n  for (var t = 0, n = 0 | r.length; t < n; t++) {\n    e = (e << 5) + e + r.charCodeAt(t);\n  }\n\n  return e;\n}\n\nfunction hash(e) {\n  return phash(5381, e) >>> 0;\n}\n\nvar i = new Set();\nvar s = new WeakMap();\n\nfunction stringify(e) {\n  if (null === e || i.has(e)) {\n    return \"null\";\n  } else if (\"object\" != typeof e) {\n    return JSON.stringify(e) || \"\";\n  } else if (e.toJSON) {\n    return stringify(e.toJSON());\n  } else if (Array.isArray(e)) {\n    var r = \"[\";\n\n    for (var t = 0, n = e.length; t < n; t++) {\n      if (t > 0) {\n        r += \",\";\n      }\n\n      var a = stringify(e[t]);\n      r += a.length > 0 ? a : \"null\";\n    }\n\n    return r += \"]\";\n  }\n\n  var o = Object.keys(e).sort();\n\n  if (!o.length && e.constructor && e.constructor !== Object) {\n    var u = s.get(e) || Math.random().toString(36).slice(2);\n    s.set(e, u);\n    return '{\"__key\":\"' + u + '\"}';\n  }\n\n  i.add(e);\n  var f = \"{\";\n\n  for (var c = 0, l = o.length; c < l; c++) {\n    var p = o[c];\n    var h = stringify(e[p]);\n\n    if (h) {\n      if (f.length > 1) {\n        f += \",\";\n      }\n\n      f += stringify(p) + \":\" + h;\n    }\n  }\n\n  i.delete(e);\n  return f += \"}\";\n}\n\nfunction stringifyVariables(e) {\n  i.clear();\n  return stringify(e);\n}\n\nvar u = /(\"{3}[\\s\\S]*\"{3}|\"(?:\\\\.|[^\"])*\")/g;\nvar f = /([\\s,]|#[^\\n\\r]+)+/g;\n\nfunction replaceOutsideStrings(e, r) {\n  return r % 2 == 0 ? e.replace(f, \" \").trim() : e;\n}\n\nfunction stringifyDocument(e) {\n  var r = (\"string\" != typeof e ? e.loc && e.loc.source.body || n(e) : e).split(u).map(replaceOutsideStrings).join(\"\");\n\n  if (\"string\" != typeof e) {\n    var t = \"definitions\" in e && getOperationName(e);\n\n    if (t) {\n      r = \"# \" + t + \"\\n\" + r;\n    }\n\n    if (!e.loc) {\n      e.loc = {\n        start: 0,\n        end: r.length,\n        source: {\n          body: r,\n          name: \"gql\",\n          locationOffset: {\n            line: 1,\n            column: 1\n          }\n        }\n      };\n    }\n  }\n\n  return r;\n}\n\nvar c = new Map();\n\nfunction keyDocument(e) {\n  var r;\n  var n;\n\n  if (\"string\" == typeof e) {\n    r = hash(stringifyDocument(e));\n    n = c.get(r) || t(e, {\n      noLocation: !0\n    });\n  } else {\n    r = e.__key || hash(stringifyDocument(e));\n    n = c.get(r) || e;\n  }\n\n  if (!n.loc) {\n    stringifyDocument(n);\n  }\n\n  n.__key = r;\n  c.set(r, n);\n  return n;\n}\n\nfunction createRequest(e, r) {\n  if (!r) {\n    r = {};\n  }\n\n  var t = keyDocument(e);\n  return {\n    key: phash(t.__key, stringifyVariables(r)) >>> 0,\n    query: t,\n    variables: r\n  };\n}\n\nfunction getOperationName(e) {\n  for (var t = 0, n = e.definitions.length; t < n; t++) {\n    var a = e.definitions[t];\n\n    if (a.kind === r.OPERATION_DEFINITION && a.name) {\n      return a.name.value;\n    }\n  }\n}\n\nfunction getOperationType(e) {\n  for (var t = 0, n = e.definitions.length; t < n; t++) {\n    var a = e.definitions[t];\n\n    if (a.kind === r.OPERATION_DEFINITION) {\n      return a.operation;\n    }\n  }\n}\n\nfunction _extends() {\n  return (_extends = Object.assign || function (e) {\n    for (var r = 1; r < arguments.length; r++) {\n      var t = arguments[r];\n\n      for (var n in t) {\n        if (Object.prototype.hasOwnProperty.call(t, n)) {\n          e[n] = t[n];\n        }\n      }\n    }\n\n    return e;\n  }).apply(this, arguments);\n}\n\nfunction makeResult(e, r, t) {\n  if (!(\"data\" in r) && !(\"errors\" in r) || \"path\" in r) {\n    throw new Error(\"No Content\");\n  }\n\n  return {\n    operation: e,\n    data: r.data,\n    error: Array.isArray(r.errors) ? new o({\n      graphQLErrors: r.errors,\n      response: t\n    }) : void 0,\n    extensions: \"object\" == typeof r.extensions && r.extensions || void 0,\n    hasNext: !!r.hasNext\n  };\n}\n\nfunction mergeResultPatch(e, r, t) {\n  var n = _extends({}, e);\n\n  n.hasNext = !!r.hasNext;\n\n  if (!(\"path\" in r)) {\n    if (\"data\" in r) {\n      n.data = r.data;\n    }\n\n    return n;\n  }\n\n  if (Array.isArray(r.errors)) {\n    n.error = new o({\n      graphQLErrors: n.error ? n.error.graphQLErrors.concat(r.errors) : r.errors,\n      response: t\n    });\n  }\n\n  var a = n.data = _extends({}, n.data);\n\n  var i = 0;\n  var s;\n\n  while (i < r.path.length) {\n    a = a[s = r.path[i++]] = Array.isArray(a[s]) ? [].concat(a[s]) : _extends({}, a[s]);\n  }\n\n  _extends(a, r.data);\n\n  return n;\n}\n\nfunction makeErrorResult(e, r, t) {\n  return {\n    operation: e,\n    data: void 0,\n    error: new o({\n      networkError: r,\n      response: t\n    }),\n    extensions: void 0\n  };\n}\n\nfunction shouldUseGet(e) {\n  return \"query\" === e.kind && !!e.context.preferGetMethod;\n}\n\nfunction makeFetchBody(e) {\n  return {\n    query: n(e.query),\n    operationName: getOperationName(e.query),\n    variables: e.variables || void 0,\n    extensions: void 0\n  };\n}\n\nfunction makeFetchURL(e, r) {\n  var t = shouldUseGet(e);\n  var n = e.context.url;\n\n  if (!t || !r) {\n    return n;\n  }\n\n  var a = [];\n\n  if (r.operationName) {\n    a.push(\"operationName=\" + encodeURIComponent(r.operationName));\n  }\n\n  if (r.query) {\n    a.push(\"query=\" + encodeURIComponent(r.query.replace(/#[^\\n\\r]+/g, \" \").trim()));\n  }\n\n  if (r.variables) {\n    a.push(\"variables=\" + encodeURIComponent(stringifyVariables(r.variables)));\n  }\n\n  if (r.extensions) {\n    a.push(\"extensions=\" + encodeURIComponent(stringifyVariables(r.extensions)));\n  }\n\n  var o = n + \"?\" + a.join(\"&\");\n\n  if (o.length > 2047) {\n    e.context.preferGetMethod = !1;\n    return n;\n  }\n\n  return o;\n}\n\nfunction makeFetchOptions(e, r) {\n  var t = shouldUseGet(e);\n  var n = {\n    accept: \"application/graphql+json, application/json\"\n  };\n\n  if (!t) {\n    n[\"content-type\"] = \"application/json\";\n  }\n\n  var a = (\"function\" == typeof e.context.fetchOptions ? e.context.fetchOptions() : e.context.fetchOptions) || {};\n\n  if (a.headers) {\n    for (var o in a.headers) {\n      n[o.toLowerCase()] = a.headers[o];\n    }\n  }\n\n  return _extends({}, a, {\n    body: !t && r ? JSON.stringify(r) : void 0,\n    method: t ? \"GET\" : \"POST\",\n    headers: n\n  });\n}\n\nvar l = \"undefined\" != typeof Symbol ? Symbol.asyncIterator : null;\nvar p = \"undefined\" != typeof TextDecoder ? new TextDecoder() : null;\nvar h = /content-type:[^\\r\\n]*application\\/json/i;\nvar d = /boundary=\"?([^=\";]+)\"?/i;\n\nfunction makeFetchSource(e, r, t) {\n  var n = \"manual\" === t.redirect ? 400 : 300;\n  var o = e.context.fetch;\n  return a(function (a) {\n    var i = a.next;\n    var s = a.complete;\n    var u = \"undefined\" != typeof AbortController ? new AbortController() : null;\n\n    if (u) {\n      t.signal = u.signal;\n    }\n\n    var f = !1;\n\n    function executeIncrementalFetch(e, r, t) {\n      var n = t.headers && t.headers.get(\"Content-Type\") || \"\";\n\n      if (/text\\//i.test(n)) {\n        return t.text().then(function (n) {\n          e(makeErrorResult(r, new Error(n), t));\n        });\n      } else if (!/multipart\\/mixed/i.test(n)) {\n        return t.text().then(function (n) {\n          e(makeResult(r, JSON.parse(n), t));\n        });\n      }\n\n      var a = \"---\";\n      var o = n.match(d);\n\n      if (o) {\n        a = \"--\" + o[1];\n      }\n\n      var i;\n\n      var cancel = function () {};\n\n      if (l && t[l]) {\n        var s = t[l]();\n        i = s.next.bind(s);\n      } else if (\"body\" in t && t.body) {\n        var u = t.body.getReader();\n        cancel = u.cancel.bind(u);\n        i = u.read.bind(u);\n      } else {\n        throw new TypeError(\"Streaming requests unsupported\");\n      }\n\n      var c = \"\";\n      var v = !0;\n      var m = null;\n      var g = null;\n      return i().then(function next(n) {\n        if (!n.done) {\n          var o = function toString(e) {\n            return \"Buffer\" === e.constructor.name ? e.toString() : p.decode(e);\n          }(n.value);\n\n          var s = o.indexOf(a);\n\n          if (s > -1) {\n            s += c.length;\n          } else {\n            s = c.indexOf(a);\n          }\n\n          c += o;\n\n          while (s > -1) {\n            var u = c.slice(0, s);\n            var l = c.slice(s + a.length);\n\n            if (v) {\n              v = !1;\n            } else {\n              var d = u.indexOf(\"\\r\\n\\r\\n\") + 4;\n              var y = u.slice(0, d);\n              var x = u.slice(d, u.lastIndexOf(\"\\r\\n\"));\n              var b = void 0;\n\n              if (h.test(y)) {\n                try {\n                  b = JSON.parse(x);\n                  m = g = g ? mergeResultPatch(g, b, t) : makeResult(r, b, t);\n                } catch (e) {}\n              }\n\n              if (\"--\" === l.slice(0, 2) || b && !b.hasNext) {\n                if (!g) {\n                  return e(makeResult(r, {}, t));\n                }\n\n                break;\n              }\n            }\n\n            s = (c = l).indexOf(a);\n          }\n        } else {\n          f = !0;\n        }\n\n        if (m) {\n          e(m);\n          m = null;\n        }\n\n        if (!n.done && (!g || g.hasNext)) {\n          return i().then(next);\n        }\n      }).finally(cancel);\n    }\n\n    var c = !1;\n    var v = !1;\n    var m;\n    Promise.resolve().then(function () {\n      if (c) {\n        return;\n      }\n\n      return (o || fetch)(r, t);\n    }).then(function (r) {\n      if (!r) {\n        return;\n      }\n\n      v = (m = r).status < 200 || m.status >= n;\n      return executeIncrementalFetch(i, e, m);\n    }).then(s).catch(function (r) {\n      if (f) {\n        throw r;\n      }\n\n      var t = makeErrorResult(e, v ? m.statusText ? new Error(m.statusText) : r : r, m);\n      i(t);\n      s();\n    });\n    return function () {\n      c = !0;\n\n      if (u) {\n        u.abort();\n      }\n    };\n  });\n}\n\nexport { o as C, _extends as _, makeErrorResult as a, makeFetchBody as b, makeFetchURL as c, makeFetchOptions as d, makeFetchSource as e, createRequest as f, getOperationType as g, stringifyVariables as h, mergeResultPatch as i, getOperationName as j, keyDocument as k, makeResult as m, stringifyDocument as s };","map":{"version":3,"mappings":";;;kBAEMA;;;AAqBH,SAAMC,qBAAN,CAAMA,CAAN,EAAMA;;;;;;;;;;;;QAmCCC;;eAENC;;YArDF;;;;;;;;;;;;;aAaIF;KAbJ;;iBA0DEC;SACKE;;;;;;;;;;;iBAIOF;;;;;;;;;AChEZG,SAAKA,KAALA,CAAIA,CAAJA,EAAIA,CAAJA,EAAIA;;;;;;;;;;ACLRC,SAAWC,IAAXD,CAAWC,CAAXD,EAAWC;;;;AAIP,QAAO,SAAP;AACD;;AAEA,SAAMC,SAAN,CAAMA,CAAN,EAAMA;oBACWC,MAACC,CAADD,GAACC;;;;SAGZC,IAAIC,QAAJD,EAAIC;WACFJ;GADFG,UACWE;;;;MAEdC;;;;;;;;;;;;;;;;;;;;;;kBAoBIC;QAAgBD;;;;;;;;;;;;;SAWxBL;;;ACvBFH;;;;;AAIgE;;;AAK9DK,SAAOK,qBAAPL,CAAOK,CAAPL,EAAOK,CAAPL,EAAOK;;;;;;;;;;;;;;WAmBKC;;;;;;;;;;;;;;;;;;;AAiBVC,YAAWC,GAAXD;;AACoCE;MAApCF;;;4BAGyBG;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;SAuChBC,iBAAoBC;OAC1BZ,IAAIC,IAAI,CAARD,EAAWa,IAAID,EAAME,WAANF,CAAkBG,QAAQd,IAAIY,GAAGZ,KAAK;QAClDe,IAAOJ,EAAME,WAANF,CAAkBX,CAAlBW;;QACTI,EAAKC,IAALD,KAAcE,EAAKC,oBAAnBH,IAAmBG;aACdH,EAAKI,IAALJ,CAAKI;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;kBCvGTC;IASLC,UAAUC,KAAVD,CAAUC,YAAVD;;;;;;;qBAYiBE;;;mCAGjBH;;;;;AAED;;;;;;;;;;;;;;cAiBgBI,IAANC,CAAMD,CAANC;qBACFL,2DADEK;gBAEGC;IAFHD,CAAMD;;;;;;;;oBAeIV;IAGrBa,IAAOC,EADPC,eACOD,IADPC,0DACAF;;;;;;;;SC7DIG;SACGX;gBAAAA;gBAAAA;;;gBAOK3B;MAPL2B;IASPY;EATOZ;;;SAaIa,aACXb;;;;AAKA,uBAAqBc,CAArB,EAAqBA;;;;eAEIA;;;;;;MAKrBC;;;;WAOKH;;;;;QAOAI;;;;;;;;;;;;;;;;;;MAuBLC;IAAeC;;;;;;;AAOfA;;;;;;;;;;;;;IC5EAC;6BACN5C;;;;SAOE6C,gBAA2B;8CAAA;8BAAA;;EAAA,CAA3BA;;;;;AAaE7C;;;;;;qBAgBKF;;;;;;;;;;;;;;;;;;;;;;;;;;;;QAwBDgD;;;;;;;UASEC,KAAJ1C;;YAES2C,EAATA,IAASA,CAATA,IAASA,CAATA,CAASA;aACFb,IAAI,qBAAJA,EAAI;kBACeK,KAAKS;+BACDC;;OAFvBf;;;;;;UASHgB;;;;kBAzDL;;WAAA;;;;;;;;;;;;;;oBA+EoBC;;;;;;;;;;;;kBAUPC;;;;;;;;;;;;;;;;;;;;QAqBVC;;;;;;;;;;;;;;YAcIC,UACLC,KAZH;UAaQC;;;;;;MAeJF","names":["generateErrorMessage","rehydrateGraphQlError","message","super","response","h","const","hash","stringify","seen","x","let","i","Array","out","l$1","replaceOutsideStrings","loc","key","stringifyDocument","noLocation","q","getOperationType","query","l","definitions","length","node","kind","Kind","OPERATION_DEFINITION","operation","result","extensions","Error","patch","path","CombinedError","prop","error","part","data","shouldUseGet","variables","makeFetchURL","request","body","push","finalUrl","headers","jsonHeaderRe","input","cancel","prevResult","next","getReader","indexOf","buffer","_error","payload","statusNotOk","complete","catch","hasResults"],"sources":["/home/tarun/Downloads/Archive/node_modules/@urql/core/src/utils/error.ts","/home/tarun/Downloads/Archive/node_modules/@urql/core/src/utils/hash.ts","/home/tarun/Downloads/Archive/node_modules/@urql/core/src/utils/stringifyVariables.ts","/home/tarun/Downloads/Archive/node_modules/@urql/core/src/utils/request.ts","/home/tarun/Downloads/Archive/node_modules/@urql/core/src/utils/result.ts","/home/tarun/Downloads/Archive/node_modules/@urql/core/src/internal/fetchOptions.ts","/home/tarun/Downloads/Archive/node_modules/@urql/core/src/internal/fetchSource.ts"],"sourcesContent":["import { GraphQLError } from 'graphql';\n\nconst generateErrorMessage = (\n  networkErr?: Error,\n  graphQlErrs?: GraphQLError[]\n) => {\n  let error = '';\n  if (networkErr !== undefined) {\n    return (error = `[Network] ${networkErr.message}`);\n  }\n\n  if (graphQlErrs !== undefined) {\n    graphQlErrs.forEach(err => {\n      error += `[GraphQL] ${err.message}\\n`;\n    });\n  }\n\n  return error.trim();\n};\n\nconst rehydrateGraphQlError = (error: any): GraphQLError => {\n  if (typeof error === 'string') {\n    return new GraphQLError(error);\n  } else if (typeof error === 'object' && error.message) {\n    return new GraphQLError(\n      error.message,\n      error.nodes,\n      error.source,\n      error.positions,\n      error.path,\n      error,\n      error.extensions || {}\n    );\n  } else {\n    return error as any;\n  }\n};\n\n/** An error which can consist of GraphQL errors and Network errors. */\nexport class CombinedError extends Error {\n  public name: string;\n  public message: string;\n  public graphQLErrors: GraphQLError[];\n  public networkError?: Error;\n  public response?: any;\n\n  constructor({\n    networkError,\n    graphQLErrors,\n    response,\n  }: {\n    networkError?: Error;\n    graphQLErrors?: Array<string | Partial<GraphQLError> | Error>;\n    response?: any;\n  }) {\n    const normalizedGraphQLErrors = (graphQLErrors || []).map(\n      rehydrateGraphQlError\n    );\n    const message = generateErrorMessage(networkError, normalizedGraphQLErrors);\n\n    super(message);\n\n    this.name = 'CombinedError';\n    this.message = message;\n    this.graphQLErrors = normalizedGraphQLErrors;\n    this.networkError = networkError;\n    this.response = response;\n  }\n\n  toString() {\n    return this.message;\n  }\n}\n","// When we have separate strings it's useful to run a progressive\n// version of djb2 where we pretend that we're still looping over\n// the same string\nexport const phash = (h: number, x: string): number => {\n  h = h | 0;\n  for (let i = 0, l = x.length | 0; i < l; i++) {\n    h = (h << 5) + h + x.charCodeAt(i);\n  }\n\n  return h;\n};\n\n// This is a djb2 hashing function\nexport const hash = (x: string): number => phash(5381 | 0, x) >>> 0;\n","const seen = new Set();\nconst cache = new WeakMap();\n\nconst stringify = (x: any): string => {\n  if (x === null || seen.has(x)) {\n    return 'null';\n  } else if (typeof x !== 'object') {\n    return JSON.stringify(x) || '';\n  } else if (x.toJSON) {\n    return stringify(x.toJSON());\n  } else if (Array.isArray(x)) {\n    let out = '[';\n    for (let i = 0, l = x.length; i < l; i++) {\n      if (i > 0) out += ',';\n      const value = stringify(x[i]);\n      out += value.length > 0 ? value : 'null';\n    }\n\n    out += ']';\n    return out;\n  }\n\n  const keys = Object.keys(x).sort();\n  if (!keys.length && x.constructor && x.constructor !== Object) {\n    const key = cache.get(x) || Math.random().toString(36).slice(2);\n    cache.set(x, key);\n    return `{\"__key\":\"${key}\"}`;\n  }\n\n  seen.add(x);\n  let out = '{';\n  for (let i = 0, l = keys.length; i < l; i++) {\n    const key = keys[i];\n    const value = stringify(x[key]);\n    if (value) {\n      if (out.length > 1) out += ',';\n      out += stringify(key) + ':' + value;\n    }\n  }\n\n  seen.delete(x);\n  out += '}';\n  return out;\n};\n\nexport const stringifyVariables = (x: any): string => {\n  seen.clear();\n  return stringify(x);\n};\n","import { TypedDocumentNode } from '@graphql-typed-document-node/core';\n\nimport {\n  Location,\n  DefinitionNode,\n  DocumentNode,\n  Kind,\n  parse,\n  print,\n} from 'graphql';\n\nimport { hash, phash } from './hash';\nimport { stringifyVariables } from './stringifyVariables';\nimport { GraphQLRequest } from '../types';\n\ninterface WritableLocation {\n  loc: Location | undefined;\n}\n\nexport interface KeyedDocumentNode extends DocumentNode {\n  __key: number;\n}\n\nconst GRAPHQL_STRING_RE = /(\"{3}[\\s\\S]*\"{3}|\"(?:\\\\.|[^\"])*\")/g;\nconst REPLACE_CHAR_RE = /([\\s,]|#[^\\n\\r]+)+/g;\n\nconst replaceOutsideStrings = (str: string, idx: number) =>\n  idx % 2 === 0 ? str.replace(REPLACE_CHAR_RE, ' ').trim() : str;\n\nexport const stringifyDocument = (\n  node: string | DefinitionNode | DocumentNode\n): string => {\n  let str = (typeof node !== 'string'\n    ? (node.loc && node.loc.source.body) || print(node)\n    : node\n  )\n    .split(GRAPHQL_STRING_RE)\n    .map(replaceOutsideStrings)\n    .join('');\n\n  if (typeof node !== 'string') {\n    const operationName = 'definitions' in node && getOperationName(node);\n    if (operationName) {\n      str = `# ${operationName}\\n${str}`;\n    }\n\n    if (!node.loc) {\n      (node as WritableLocation).loc = {\n        start: 0,\n        end: str.length,\n        source: {\n          body: str,\n          name: 'gql',\n          locationOffset: { line: 1, column: 1 },\n        },\n      } as Location;\n    }\n  }\n\n  return str;\n};\n\nconst docs = new Map<number, KeyedDocumentNode>();\n\nexport const keyDocument = (q: string | DocumentNode): KeyedDocumentNode => {\n  let key: number;\n  let query: DocumentNode;\n  if (typeof q === 'string') {\n    key = hash(stringifyDocument(q));\n    query = docs.get(key) || parse(q, { noLocation: true });\n  } else {\n    key = (q as KeyedDocumentNode).__key || hash(stringifyDocument(q));\n    query = docs.get(key) || q;\n  }\n\n  // Add location information if it's missing\n  if (!query.loc) stringifyDocument(query);\n\n  (query as KeyedDocumentNode).__key = key;\n  docs.set(key, query as KeyedDocumentNode);\n  return query as KeyedDocumentNode;\n};\n\nexport const createRequest = <Data = any, Variables = object>(\n  q: string | DocumentNode | TypedDocumentNode<Data, Variables>,\n  vars?: Variables\n): GraphQLRequest<Data, Variables> => {\n  if (!vars) vars = {} as Variables;\n  const query = keyDocument(q);\n  return {\n    key: phash(query.__key, stringifyVariables(vars)) >>> 0,\n    query,\n    variables: vars,\n  };\n};\n\n/**\n * Finds the Name value from the OperationDefinition of a Document\n */\nexport const getOperationName = (query: DocumentNode): string | undefined => {\n  for (let i = 0, l = query.definitions.length; i < l; i++) {\n    const node = query.definitions[i];\n    if (node.kind === Kind.OPERATION_DEFINITION && node.name) {\n      return node.name.value;\n    }\n  }\n};\n\n/**\n * Finds the operation-type\n */\nexport const getOperationType = (query: DocumentNode): string | undefined => {\n  for (let i = 0, l = query.definitions.length; i < l; i++) {\n    const node = query.definitions[i];\n    if (node.kind === Kind.OPERATION_DEFINITION) {\n      return node.operation;\n    }\n  }\n};\n","import { ExecutionResult, Operation, OperationResult } from '../types';\nimport { CombinedError } from './error';\n\nexport const makeResult = (\n  operation: Operation,\n  result: ExecutionResult,\n  response?: any\n): OperationResult => {\n  if ((!('data' in result) && !('errors' in result)) || 'path' in result) {\n    throw new Error('No Content');\n  }\n\n  return {\n    operation,\n    data: result.data,\n    error: Array.isArray(result.errors)\n      ? new CombinedError({\n          graphQLErrors: result.errors,\n          response,\n        })\n      : undefined,\n    extensions:\n      (typeof result.extensions === 'object' && result.extensions) || undefined,\n    hasNext: !!result.hasNext,\n  };\n};\n\nexport const mergeResultPatch = (\n  prevResult: OperationResult,\n  patch: ExecutionResult,\n  response?: any\n): OperationResult => {\n  const result = { ...prevResult };\n  result.hasNext = !!patch.hasNext;\n\n  if (!('path' in patch)) {\n    if ('data' in patch) result.data = patch.data;\n    return result;\n  }\n\n  if (Array.isArray(patch.errors)) {\n    result.error = new CombinedError({\n      graphQLErrors: result.error\n        ? [...result.error.graphQLErrors, ...patch.errors]\n        : patch.errors,\n      response,\n    });\n  }\n\n  let part: Record<string, any> | Array<any> = (result.data = {\n    ...result.data,\n  });\n\n  let i = 0;\n  let prop: string | number;\n  while (i < patch.path.length) {\n    prop = patch.path[i++];\n    part = part[prop] = Array.isArray(part[prop])\n      ? [...part[prop]]\n      : { ...part[prop] };\n  }\n\n  Object.assign(part, patch.data);\n  return result;\n};\n\nexport const makeErrorResult = (\n  operation: Operation,\n  error: Error,\n  response?: any\n): OperationResult => ({\n  operation,\n  data: undefined,\n  error: new CombinedError({\n    networkError: error,\n    response,\n  }),\n  extensions: undefined,\n});\n","import { DocumentNode, print } from 'graphql';\n\nimport { getOperationName, stringifyVariables } from '../utils';\nimport { Operation } from '../types';\n\nexport interface FetchBody {\n  query?: string;\n  operationName: string | undefined;\n  variables: undefined | Record<string, any>;\n  extensions: undefined | Record<string, any>;\n}\n\nconst shouldUseGet = (operation: Operation): boolean => {\n  return operation.kind === 'query' && !!operation.context.preferGetMethod;\n};\n\nexport const makeFetchBody = (request: {\n  query: DocumentNode;\n  variables?: object;\n}): FetchBody => ({\n  query: print(request.query),\n  operationName: getOperationName(request.query),\n  variables: request.variables || undefined,\n  extensions: undefined,\n});\n\nexport const makeFetchURL = (\n  operation: Operation,\n  body?: FetchBody\n): string => {\n  const useGETMethod = shouldUseGet(operation);\n  const url = operation.context.url;\n  if (!useGETMethod || !body) return url;\n\n  const search: string[] = [];\n  if (body.operationName) {\n    search.push('operationName=' + encodeURIComponent(body.operationName));\n  }\n\n  if (body.query) {\n    search.push(\n      'query=' +\n        encodeURIComponent(body.query.replace(/#[^\\n\\r]+/g, ' ').trim())\n    );\n  }\n\n  if (body.variables) {\n    search.push(\n      'variables=' + encodeURIComponent(stringifyVariables(body.variables))\n    );\n  }\n\n  if (body.extensions) {\n    search.push(\n      'extensions=' + encodeURIComponent(stringifyVariables(body.extensions))\n    );\n  }\n\n  const finalUrl = `${url}?${search.join('&')}`;\n\n  if (finalUrl.length > 2047) {\n    operation.context.preferGetMethod = false;\n    return url;\n  }\n\n  return finalUrl;\n};\n\nexport const makeFetchOptions = (\n  operation: Operation,\n  body?: FetchBody\n): RequestInit => {\n  const useGETMethod = shouldUseGet(operation);\n  const headers: HeadersInit = {\n    accept: 'application/graphql+json, application/json',\n  };\n  if (!useGETMethod) headers['content-type'] = 'application/json';\n  const extraOptions =\n    (typeof operation.context.fetchOptions === 'function'\n      ? operation.context.fetchOptions()\n      : operation.context.fetchOptions) || {};\n  if (extraOptions.headers)\n    for (const key in extraOptions.headers)\n      headers[key.toLowerCase()] = extraOptions.headers[key];\n  return {\n    ...extraOptions,\n    body: !useGETMethod && body ? JSON.stringify(body) : undefined,\n    method: useGETMethod ? 'GET' : 'POST',\n    headers,\n  };\n};\n","import { Source, make } from 'wonka';\nimport { Operation, OperationResult } from '../types';\nimport { makeResult, makeErrorResult, mergeResultPatch } from '../utils';\n\nconst asyncIterator =\n  typeof Symbol !== 'undefined' ? Symbol.asyncIterator : null;\nconst decoder = typeof TextDecoder !== 'undefined' ? new TextDecoder() : null;\nconst jsonHeaderRe = /content-type:[^\\r\\n]*application\\/json/i;\nconst boundaryHeaderRe = /boundary=\"?([^=\";]+)\"?/i;\n\ntype ChunkData = { done: false; value: Buffer | Uint8Array } | { done: true };\n\n// NOTE: We're avoiding referencing the `Buffer` global here to prevent\n// auto-polyfilling in Webpack\nconst toString = (input: Buffer | ArrayBuffer): string =>\n  input.constructor.name === 'Buffer'\n    ? (input as Buffer).toString()\n    : decoder!.decode(input as ArrayBuffer);\n\nexport const makeFetchSource = (\n  operation: Operation,\n  url: string,\n  fetchOptions: RequestInit\n): Source<OperationResult> => {\n  const maxStatus = fetchOptions.redirect === 'manual' ? 400 : 300;\n  const fetcher = operation.context.fetch;\n\n  return make<OperationResult>(({ next, complete }) => {\n    const abortController =\n      typeof AbortController !== 'undefined' ? new AbortController() : null;\n    if (abortController) {\n      fetchOptions.signal = abortController.signal;\n    }\n\n    let hasResults = false;\n    // DERIVATIVE: Copyright (c) 2021 Marais Rossouw <hi@marais.io>\n    // See: https://github.com/maraisr/meros/blob/219fe95/src/browser.ts\n    const executeIncrementalFetch = (\n      onResult: (result: OperationResult) => void,\n      operation: Operation,\n      response: Response\n    ): Promise<void> => {\n      // NOTE: Guarding against fetch polyfills here\n      const contentType =\n        (response.headers && response.headers.get('Content-Type')) || '';\n      if (/text\\//i.test(contentType)) {\n        return response.text().then(text => {\n          onResult(makeErrorResult(operation, new Error(text), response));\n        });\n      } else if (!/multipart\\/mixed/i.test(contentType)) {\n        return response.text().then(payload => {\n          onResult(makeResult(operation, JSON.parse(payload), response));\n        });\n      }\n\n      let boundary = '---';\n      const boundaryHeader = contentType.match(boundaryHeaderRe);\n      if (boundaryHeader) boundary = '--' + boundaryHeader[1];\n\n      let read: () => Promise<ChunkData>;\n      let cancel = () => {\n        /*noop*/\n      };\n      if (asyncIterator && response[asyncIterator]) {\n        const iterator = response[asyncIterator]();\n        read = iterator.next.bind(iterator);\n      } else if ('body' in response && response.body) {\n        const reader = response.body.getReader();\n        cancel = reader.cancel.bind(reader);\n        read = reader.read.bind(reader);\n      } else {\n        throw new TypeError('Streaming requests unsupported');\n      }\n\n      let buffer = '';\n      let isPreamble = true;\n      let nextResult: OperationResult | null = null;\n      let prevResult: OperationResult | null = null;\n\n      function next(data: ChunkData): Promise<void> | void {\n        if (!data.done) {\n          const chunk = toString(data.value);\n          let boundaryIndex = chunk.indexOf(boundary);\n          if (boundaryIndex > -1) {\n            boundaryIndex += buffer.length;\n          } else {\n            boundaryIndex = buffer.indexOf(boundary);\n          }\n\n          buffer += chunk;\n          while (boundaryIndex > -1) {\n            const current = buffer.slice(0, boundaryIndex);\n            const next = buffer.slice(boundaryIndex + boundary.length);\n\n            if (isPreamble) {\n              isPreamble = false;\n            } else {\n              const headersEnd = current.indexOf('\\r\\n\\r\\n') + 4;\n              const headers = current.slice(0, headersEnd);\n              const body = current.slice(\n                headersEnd,\n                current.lastIndexOf('\\r\\n')\n              );\n\n              let payload: any;\n              if (jsonHeaderRe.test(headers)) {\n                try {\n                  payload = JSON.parse(body);\n                  nextResult = prevResult = prevResult\n                    ? mergeResultPatch(prevResult, payload, response)\n                    : makeResult(operation, payload, response);\n                } catch (_error) {}\n              }\n\n              if (next.slice(0, 2) === '--' || (payload && !payload.hasNext)) {\n                if (!prevResult)\n                  return onResult(makeResult(operation, {}, response));\n                break;\n              }\n            }\n\n            buffer = next;\n            boundaryIndex = buffer.indexOf(boundary);\n          }\n        } else {\n          hasResults = true;\n        }\n\n        if (nextResult) {\n          onResult(nextResult);\n          nextResult = null;\n        }\n\n        if (!data.done && (!prevResult || prevResult.hasNext)) {\n          return read().then(next);\n        }\n      }\n\n      return read().then(next).finally(cancel);\n    };\n\n    let ended = false;\n    let statusNotOk = false;\n    let response: Response;\n\n    Promise.resolve()\n      .then(() => {\n        if (ended) return;\n        return (fetcher || fetch)(url, fetchOptions);\n      })\n      .then((_response: Response | void) => {\n        if (!_response) return;\n        response = _response;\n        statusNotOk = response.status < 200 || response.status >= maxStatus;\n        return executeIncrementalFetch(next, operation, response);\n      })\n      .then(complete)\n      .catch((error: Error) => {\n        if (hasResults) {\n          throw error;\n        }\n\n        const result = makeErrorResult(\n          operation,\n          statusNotOk\n            ? response.statusText\n              ? new Error(response.statusText)\n              : error\n            : error,\n          response\n        );\n\n        next(result);\n        complete();\n      });\n\n    return () => {\n      ended = true;\n      if (abortController) {\n        abortController.abort();\n      }\n    };\n  });\n};\n"]},"metadata":{},"sourceType":"module"}